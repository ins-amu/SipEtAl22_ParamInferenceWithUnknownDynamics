{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e942664a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import scipy.signal as sig\n",
    "import scipy.io as spio\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import networkx as nx\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "sys.path.append(\"../../ndsvae/\")\n",
    "import ndsvae as ndsv\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import util\n",
    "import plotutils as pu\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6b07a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"ns_3_mreg_3_msub_0_nf_32\"\n",
    "conn = \"linw\"\n",
    "preproc = \"dicer\"\n",
    "modelname = \"AB\"\n",
    "\n",
    "ds = ndsv.Dataset.from_file(f\"../run/hcp/hcp100_{conn}_{preproc}/dataset.npz\")\n",
    "run = util.select_run_fc(f\"hcp100_{conn}_{preproc}\", modelname, config, [0,1], \"hcp\")\n",
    "direc = f\"../run/hcp/hcp100_{conn}_{preproc}/model{modelname}/{config}/run{run:02d}\"\n",
    "params = util.load_params(os.path.join(direc, \"parameters\"), np.r_[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f127c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46194c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsub, nreg, _, nt = ds.y.shape\n",
    "subjects = np.r_[:nsub]\n",
    "regions = np.r_[:nreg]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4475fc3a",
   "metadata": {},
   "source": [
    "### Build dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c0dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(itertools.product(subjects, regions)), columns=['subject', 'region'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29e8e21",
   "metadata": {},
   "source": [
    "### Structural properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9fd790",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['instrength']  = np.sum(ds.w, axis=2).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af74078e",
   "metadata": {},
   "outputs": [],
   "source": [
    "centrality = np.zeros((nsub, nreg))\n",
    "\n",
    "for i in range(nsub):\n",
    "    w = nx.from_numpy_array(ds.w[i])\n",
    "    cent = nx.eigenvector_centrality_numpy(w, weight='weight')\n",
    "    centrality[i][list(cent.keys())] = list(cent.values())\n",
    "\n",
    "df['centrality'] = centrality.ravel()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce7a0ec",
   "metadata": {},
   "source": [
    "### Functional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c67fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['pca1', 'pca2', 'pca3', 'pca4', 'pca5']] = 0.\n",
    "df['corr_with_mean'] = 0.\n",
    "df['corr_with_input'] = 0.\n",
    "df['mean_fc'] = 0.\n",
    "\n",
    "for i in range(nsub):\n",
    "    ncomp = 5\n",
    "    y = ds.y[i,:,0,:].T              # (n_samples, n_features)\n",
    "    pca = PCA(n_components=ncomp).fit(y)\n",
    "    mask = (df.subject == i)    \n",
    "    ymean = np.mean(y, axis=1)    \n",
    "    ybar = pca.transform(y)\n",
    "        \n",
    "    for icomp in range(5):\n",
    "        sign = 1 if (np.corrcoef(ybar[:,icomp], ymean)[0,1] > 0) else -1\n",
    "        df.loc[mask, f\"pca{icomp+1}\"] = sign * pca.components_[icomp]    \n",
    "        \n",
    "    df.loc[mask, 'corr_with_mean']  = np.corrcoef(y.T, np.mean(y, axis=1))[-1,:-1]\n",
    "    df.loc[mask, 'corr_with_input'] = np.corrcoef(y.T, params.us[i,:,0])[-1,:-1]\n",
    "    \n",
    "    fc = np.corrcoef(y.T)\n",
    "    df.loc[mask, 'mean_fc'] = np.mean(fc, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347aedec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['corr_with_network_input'] = 0.\n",
    "df['corr_with_neighbor'] = 0.\n",
    "\n",
    "for i in range(nsub):\n",
    "    w = ds.w[i]\n",
    "    y = ds.y[i,:,0,:]\n",
    "    unet = w @ y\n",
    "    uneigh = y[np.argmax(w, axis=1),:]\n",
    "    \n",
    "    mask = (df.subject == i)\n",
    "    df.loc[mask, 'corr_with_network_input'] = [np.corrcoef(y[j], unet[j])[0,1] for j in range(nreg)]\n",
    "    df.loc[mask, 'corr_with_neighbor']      = [np.corrcoef(y[j], uneigh[j])[0,1] for j in range(nreg)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58eaf9b9",
   "metadata": {},
   "source": [
    "### Signal properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fae14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['mean', 'variance', 'skewness', 'kurtosis']] = 0.\n",
    "\n",
    "for i in range(nsub):\n",
    "    y = ds.y[i,:,0,:]\n",
    "    mask = (df.subject == i)    \n",
    "    df.loc[mask, 'mean'] = np.mean(y, axis=1)\n",
    "    df.loc[mask, 'variance'] = np.var(y, axis=1)\n",
    "    df.loc[mask, 'skewness'] = stats.skew(y, axis=1)\n",
    "    df.loc[mask, 'kurtosis'] = stats.kurtosis(y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c7f3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_crossings(y):\n",
    "    # At first axis\n",
    "    above = (y > 0)\n",
    "    return np.sum(above[1:] != above[:-1], axis=0)\n",
    "\n",
    "df[\"zero_crossings\"] = 0\n",
    "\n",
    "for i in range(nsub):\n",
    "    y = ds.y[i,:,0,:].T\n",
    "    df.loc[(df.subject == i), \"zero_crossings\"] = zero_crossings(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fae96b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# power in different bands\n",
    "T = 0.720\n",
    "freq_boundary = 0.1\n",
    "\n",
    "df[\"power_high\"] = 0.\n",
    "df[\"power_low\"] = 0.\n",
    "\n",
    "for i in range(nsub):\n",
    "    y = ds.y[i,:,0,:]   \n",
    "    freqs, psd = sig.welch(y, 1/T, scaling='density', nperseg=128)\n",
    "    mask = (df.subject == i)\n",
    "    low_freq = (freqs < freq_boundary)\n",
    "   \n",
    "    df.loc[mask, 'power_high']  = np.sum(psd[:, ~low_freq], axis=1)\n",
    "    df.loc[mask, 'power_low'] = np.sum(psd[:, low_freq], axis=1)\n",
    "    # df.loc[mask, 'Peak frequency above 0.1 Hz'] = freqs[~low_freq][np.argmax(psd[:, ~low_freq], axis=1)]\n",
    "    # df.loc[mask, 'Peak frequency below 0.1 Hz'] = freqs[low_freq][np.argmax(psd[:, low_freq], axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5204fcb",
   "metadata": {},
   "source": [
    "### Von Economo-Koskinas data from Wang et al. (2019)\n",
    "\n",
    "https://github.com/ThomasYeoLab/CBIG/tree/master/stable_projects/fMRI_dynamics/Wang2018_MFMem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c5a7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spio.loadmat(\"../etc/WangEtAl19/ECONOMO_data_Martijn.mat\")\n",
    "\n",
    "layers = ['I', 'II', 'III', 'IV', 'V', 'VI']\n",
    "neuronal_size = np.nanmean([data[f\"layer{layer}total_cell_content_cellsize_aparc\"][0] for layer in layers], axis=0)\n",
    "neuronal_density = np.nanmean([data[f\"layer{layer}total_cell_content_mm3_aparc\"][0] for layer in layers], axis=0)\n",
    "\n",
    "df['neuronal_size'] = 0.\n",
    "df['neuronal_density'] = 0.\n",
    "\n",
    "for i in range(nsub):\n",
    "    mask = (df.subject == i)\n",
    "    df.loc[mask, 'neuronal_size'] = np.concatenate([neuronal_size, neuronal_size])\n",
    "    df.loc[mask, 'neuronal_density'] = np.concatenate([neuronal_density, neuronal_density])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe13012e",
   "metadata": {},
   "source": [
    "### Myelin, RSFC gradient, and gene expression data from Kong et al. (2021)\n",
    "\n",
    "https://github.com/ThomasYeoLab/CBIG/tree/master/stable_projects/fMRI_dynamics/Kong2021_pMFM/input/Desikan_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d6c3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "myelin = np.loadtxt(\"../etc/KongEtAl21/myelin.csv\")\n",
    "rsfc_gradient = np.loadtxt(\"../etc/KongEtAl21/rsfc_gradient.csv\")\n",
    "\n",
    "df['myelin'] = 0.\n",
    "df['rsfc_gradient'] = 0.\n",
    "\n",
    "for i in range(nsub):\n",
    "    mask = (df.subject == i)\n",
    "    df.loc[mask, 'myelin'] = myelin\n",
    "    df.loc[mask, 'rsfc_gradient'] = rsfc_gradient\n",
    "    \n",
    "    \n",
    "data = spio.loadmat(\"../etc/KongEtAl21/gene_data.mat\")\n",
    "for i in range(nsub):\n",
    "    mask = (df.subject == i)\n",
    "    df.loc[mask, 'kong_pc'] = data['PC1'][:,0]\n",
    "    df.loc[mask, 'kong_pvalb_sst'] = data['PVALB'][:,0] - data['SST'][:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5484cf",
   "metadata": {},
   "source": [
    "### Corrected Von Economo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbee234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nanaverage(x, weights):\n",
    "    return np.nansum(x*weights) / ((~np.isnan(x)) * weights).sum()\n",
    "\n",
    "\n",
    "region_names = np.genfromtxt(\"../data/100307/region_names.txt\", usecols=(0), dtype=str)\n",
    "region_names = [r[7:] for r in region_names[:34]]\n",
    "\n",
    "dfve = pd.read_csv(\"../etc/VonEconomo/table_dk34.csv\")\n",
    "\n",
    "dfg = dfve.groupby(['area'])\n",
    "dfve = pd.concat([\n",
    "    dfg.apply(lambda x: np.nansum(x.thickness)),\n",
    "    dfg.apply(lambda x: nanaverage(x.density,  weights=x.thickness)),\n",
    "    dfg.apply(lambda x: nanaverage(x.cellsize, weights=x.thickness))\n",
    "    ], axis=1, keys=['thickness', 'density', 'cellsize'])\n",
    "\n",
    "# Sort\n",
    "dfve = dfve.loc[region_names].reset_index()\n",
    "\n",
    "# Add to the dataframe\n",
    "for i in range(nsub):\n",
    "    mask = (df.subject == i)\n",
    "    df.loc[mask, 'neuronal_size_corr'] = np.concatenate([dfve.cellsize, dfve.cellsize])\n",
    "    df.loc[mask, 'neuronal_density_corr'] = np.concatenate([dfve.density, dfve.density])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-practitioner",
   "metadata": {},
   "source": [
    "### BigBrain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-format",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bb(filename):\n",
    "    bb = pd.read_excel(filename, index_col=0)\n",
    "    bb['area'] = [r.replace(\"right \", \"ctx-rh-\").replace(\"left \", \"ctx-lh-\").replace(' ', '') for r in bb.region]\n",
    "    bb = bb.set_index(\"area\")    \n",
    "    \n",
    "    region_names = np.genfromtxt(\"../data/100307/region_names.txt\", usecols=(0), dtype=str)\n",
    "    \n",
    "    bb = bb.reindex(region_names)\n",
    "    return bb\n",
    "\n",
    "\n",
    "\n",
    "bb = read_bb(\"../etc/BigBrain/DESIKAN_KILLIANY_2006_density_estimates.xlsx\")\n",
    "density = bb[[f'layer {j}' for j in range(1,7)]].values\n",
    "pca = PCA(n_components=6)\n",
    "y = pca.fit_transform(density)\n",
    "\n",
    "\n",
    "df['neuronal_density_bb'] = 0.\n",
    "df['neuronal_density_bb_1'] = 0.\n",
    "df['neuronal_density_bb_2'] = 0.\n",
    "df['neuronal_density_bb_3'] = 0.\n",
    "df['neuronal_density_bb_4'] = 0.\n",
    "df['neuronal_density_bb_5'] = 0.\n",
    "df['neuronal_density_bb_6'] = 0.\n",
    "\n",
    "df['bb_pca_1'] = 0.\n",
    "df['bb_pca_2'] = 0.\n",
    "\n",
    "for i in range(nsub):\n",
    "    mask = (df.subject == i)\n",
    "    df.loc[mask, 'neuronal_density_bb'] = 1000*bb.cortex.values\n",
    "    for j in range(1,7):\n",
    "        df.loc[mask, f'neuronal_density_bb_{j}'] = 1000*bb[f'layer {j}'].values\n",
    "    \n",
    "    df.loc[mask, 'bb_pca_1'] = y[:,0]\n",
    "    df.loc[mask, 'bb_pca_2'] = y[:,1]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0eb6d1",
   "metadata": {},
   "source": [
    "### Deco et al. (2021) data\n",
    "\n",
    "https://github.com/KevinAquino/HNM/tree/main/InputData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afed6132",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = spio.loadmat(\"../etc/DecoEtAl21/APARC_genedata.mat\")['data']                     # PC\n",
    "t1t2 = spio.loadmat(\"../etc/DecoEtAl21/myelin_HCP_dk68.mat\")['t1t2Cortex'][0]         # T1w:T2w\n",
    "\n",
    "# See GranModelOptimization/slurm.sbatch_genes_balanced_gain.m in https://github.com/KevinAquino/HNM\n",
    "data = spio.loadmat(\"../etc/DecoEtAl21/DKcortex_selectedGenes.mat\")['expMeasures']    # E:I\n",
    "\n",
    "# Matlab index: 18-25 (18:21 ampa+ 22:25 nmda/gaba)\n",
    "# Matlab indexes from 1 and includes last element\n",
    "coef_e = np.sum(data[:, 17:25], axis=1)\n",
    "coef_i = np.sum(data[:, np.r_[1:9,11:14]], axis=1)\n",
    "\n",
    "ratio_e = coef_e / np.max(coef_e)\n",
    "ratio_i = coef_i / np.max(coef_i)\n",
    "ratio_ei = ratio_e / ratio_i\n",
    "\n",
    "df['deco_pc'] = 0.\n",
    "df['deco_t1t2'] = 0.\n",
    "df['deco_ei'] = 0.\n",
    "\n",
    "for i in range(nsub):\n",
    "    mask = (df.subject == i)\n",
    "    df.loc[mask, 'deco_pc'] = np.concatenate([pc, pc])\n",
    "    df.loc[mask, 'deco_t1t2'] = t1t2\n",
    "    df.loc[mask, 'deco_ei'] = np.concatenate([ratio_ei, ratio_ei])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f6e8e3",
   "metadata": {},
   "source": [
    "### Inferred parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b1cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mreg = params.thetareg.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be4de30",
   "metadata": {},
   "outputs": [],
   "source": [
    "params.thetareg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32077a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(mreg):\n",
    "    df[f'thetareg{i}_mu']  = params.thetareg[:,:,i,0].ravel()\n",
    "    df[f'thetareg{i}_std'] = params.thetareg[:,:,i,1].ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f394c3",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c321fa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "nsamples = 1\n",
    "dfs = df.loc[df.index.repeat(nsamples)]\n",
    "\n",
    "dfs['thetareg0'] = dfs.thetareg0_mu # + dfs.thetareg0_std*np.random.normal(0, 1, size=len(dfs))\n",
    "dfs['thetareg1'] = dfs.thetareg1_mu # + dfs.thetareg1_std*np.random.normal(0, 1, size=len(dfs))\n",
    "dfs['thetareg2'] = dfs.thetareg2_mu # + dfs.thetareg2_std*np.random.normal(0, 1, size=len(dfs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b64e2ce",
   "metadata": {},
   "source": [
    "## Correlations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d738bca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = np.array([0,1,2]) # Check Fig_HCP_ParamSpaceReg for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6580e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = ['thetareg0_mu', 'thetareg1_mu', 'thetareg2_mu']\n",
    "\n",
    "feature_groups = [\n",
    "    (\"Individual data\", [        \n",
    "        (\"SC: Node in-strength\", 'instrength'),\n",
    "        (\"SC: Node centrality\", \"centrality\"),\n",
    "        (\"fMRI: First PCA eigenvector\", \"pca1\"), \n",
    "        (\"fMRI: Second PCA eigenvector\", \"pca2\"),\n",
    "        (\"fMRI: Correlation with mean signal\", \"corr_with_mean\"),\n",
    "        (\"fMRI: Correlation with network input\", \"corr_with_network_input\"),\n",
    "        (\"fMRI: Number of zero-crossings\", \"zero_crossings\"),\n",
    "        (\"fMRI: Power below 0.1 Hz\", \"power_low\")\n",
    "    ]),\n",
    "    (\"External data\", [\n",
    "        (\"Neuronal size (Von Economo)\", \"neuronal_size_corr\"),\n",
    "        (\"Neuronal density (Von Economo)\", \"neuronal_density_corr\"),        \n",
    "        (\"Neuronal density (Big Brain)\", \"neuronal_density_bb\"),\n",
    "        (\"RSFC principal gradient\", \"rsfc_gradient\"),        \n",
    "        (\"T1w/T2w ratio\", \"myelin\"),\n",
    "        (\"Gene expression map (first PC)\", \"deco_pc\"),\n",
    "        (\"EI map\", \"deco_ei\"),\n",
    "    ])\n",
    "]\n",
    "\n",
    "\n",
    "pthr = 0.001\n",
    "ncomp = 3 * sum([len(features) for _, features in feature_groups])\n",
    "pthr_bonf = pthr / ncomp\n",
    "\n",
    "print(f\"p threshold: {pthr}\")\n",
    "print(f\"Num comparisons: {ncomp}\")\n",
    "print(f\"Bonferroni-corrected threshold: {pthr_bonf}\")\n",
    "\n",
    "\n",
    "for group_name, features in feature_groups:\n",
    "    print(f\"    {group_name}\")\n",
    "    for (label, feature) in features:\n",
    "        norm_feature = df[feature].copy()\n",
    "        norm_feature -= np.mean(norm_feature)\n",
    "        norm_feature /= np.std(norm_feature)\n",
    "        \n",
    "        mod = sm.OLS(norm_feature, sm.add_constant(df[parameters], prepend=False))\n",
    "        fii = mod.fit()\n",
    "        r2 = fii.rsquared_adj\n",
    "        p_values = fii.summary2().tables[1]['P>|t|'][:3][order]\n",
    "        weights = fii.summary2().tables[1]['Coef.'][:3][order]\n",
    "        \n",
    "        print(f\"    & {label:30s} &\", end=\"\")\n",
    "        print(f\"\\\\textbf{{{r2:.2f}}}\" if r2 > 0.3 else f\"        {r2:.2f} \" , end=\" \")\n",
    "        for i in range(len(parameters)):\n",
    "            val = weights[i]\n",
    "            pval = p_values[i]\n",
    "            \n",
    "            if pval >= pthr:\n",
    "                print(f\"& \\\\textcolor{{gray}}{{{val:6.2f}}}\", end=\"\")\n",
    "            elif r2 > 0.3 and np.abs(val) > 0.2:\n",
    "                print(f\"& \\\\textbf{{{val:6.2f}}}\", end=\"\")\n",
    "            else:\n",
    "                print(f\"& {val:6.2f}\", end=\"\")\n",
    "        print(\"  \\\\\\\\\")\n",
    "        \n",
    "    print(\"    \\hline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f855930c",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2910e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = \"sans-serif\"\n",
    "plt.rcParams['font.sans-serif'] = \"Arial\"\n",
    "\n",
    "SMALL_SIZE = 8\n",
    "MEDIUM_SIZE = 10\n",
    "BIGGER_SIZE = 12\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=SMALL_SIZE)     # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fc439d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fii.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb136995",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def break_text(label):\n",
    "    if len(label) > 14 and (' ' in label):\n",
    "        spaces = np.array([i for i, ch in enumerate(label) if ch == ' '])\n",
    "        best_space = spaces[np.argmin(np.abs(spaces - len(label)/2))]\n",
    "        label = label[:best_space] + '\\n' + label[best_space+1:]\n",
    "    return label\n",
    "\n",
    "\n",
    "def pvalstr(p):\n",
    "    if p < 1e-10:\n",
    "        return \"< 1e-10\"\n",
    "    else:\n",
    "        return f\"= {p:.1e}\"\n",
    "\n",
    "    \n",
    "# Mask for downsample visualization\n",
    "mask = np.array(int(0.2*len(df)) * [True] + int(0.8*len(df))*[False])\n",
    "np.random.shuffle(mask)    \n",
    "    \n",
    "for group_name, features in feature_groups:    \n",
    "    plt.figure(figsize=(8, 1.5*len(features)), dpi=150)    \n",
    "    \n",
    "    gs = matplotlib.gridspec.GridSpec(len(features), 5, width_ratios=[1,1,1,1,1], hspace=0.6, wspace=0.5,\n",
    "                                     top=0.99, bottom=0.04, left=0.12, right=1.0)\n",
    "\n",
    "    for i, (label, feature) in enumerate(features):\n",
    "        # Parameter plots\n",
    "        for j in range(3):\n",
    "            plt.subplot(gs[i,j])\n",
    "            p = order[j]\n",
    "            s = plt.scatter(df[f\"thetareg{p}_mu\"][mask], df[feature][mask], s=1, color='k', alpha=0.2)\n",
    "            plt.xlabel(f\"$\\\\theta^r_{j+1}$\")\n",
    "            if j == 0:\n",
    "                plt.ylabel(break_text(label))\n",
    "            plt.xlim(-3,3)\n",
    "            plt.xticks([-2,0,2])\n",
    "        \n",
    "        # Optimal projection\n",
    "        norm_feature = df[feature].copy()\n",
    "        norm_feature -= np.mean(norm_feature)\n",
    "        norm_feature /= np.std(norm_feature)        \n",
    "        mod = sm.OLS(norm_feature, sm.add_constant(df[parameters], prepend=False))\n",
    "        fii = mod.fit()\n",
    "        r2 = fii.rsquared_adj\n",
    "        p_values = fii.summary2().tables[1]['P>|t|'][:3][order]\n",
    "        weights = fii.summary2().tables[1]['Coef.'][:3]\n",
    "        \n",
    "        treg_p = np.sum(df[parameters].to_numpy() * weights.to_numpy(), axis=1)\n",
    "        plt.subplot(gs[i,3])\n",
    "        s = plt.scatter(treg_p[mask], df[feature][mask], s=1, color='k', alpha=0.2)\n",
    "        # plt.xlim(-3,3)\n",
    "        \n",
    "        w = weights[order]\n",
    "        plt.xlabel(f\"{w[0]:.2f} $\\\\theta^r_{1}$ {w[1]:+.2f} $\\\\theta^r_{2}$ {w[2]:+.2f} $\\\\theta^r_{3}$\")\n",
    "        \n",
    "        # Statistics\n",
    "        ax = plt.subplot(gs[i,4])\n",
    "        plt.xlim(0,1)\n",
    "        plt.ylim(0,1)\n",
    "        plt.text(0.0, 0.90, f\"$p_{{\\\\theta^r_1}}$ {pvalstr(p_values[0])}\", ha='left', va='center')\n",
    "        plt.text(0.0, 0.70, f\"$p_{{\\\\theta^r_2}}$ {pvalstr(p_values[1])}\", ha='left', va='center')\n",
    "        plt.text(0.0, 0.50, f\"$p_{{\\\\theta^r_3}}$ {pvalstr(p_values[2])}\", ha='left', va='center')\n",
    "        plt.text(0.0, 0.30, f\"$R^2$  = {r2:.2f}\", ha='left', va='center')\n",
    "        ax.axis('off')        \n",
    "            \n",
    "    \n",
    "    pu.Background(visible=False)\n",
    "    plt.savefig(f\"img/Fig_features_{group_name.replace(' ', '_')}.pdf\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24142815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9840779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d408db3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587d8c55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e632cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
